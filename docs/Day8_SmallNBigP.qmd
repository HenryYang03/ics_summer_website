---
title: "Day 8 - A Gentle Intro To Small n Big P"
author: "Zhaoxia Yu, Department of Statistics, University of California, Irvine"
date: "`r Sys.Date()`"
format: 
  revealjs:
    scrollable: true
    theme: "sky"
    slideNumber: true
    transition: "fade"
    progress: true
    controls: true
    code-fold: true
    echo: true
    R.options:
      fig-align: center
---

## Load Libraries

```{r}
library(ggplot2)
library(tidyverse)
library(googlesheets4) # the package to read google sheets. I used this package in class when reading data from a google sheet
```

## Experiment: I can predict your number
- Please enter a number (any number you prefer to enter). 
- Please use this link: [google sheet](https://docs.google.com/spreadsheets/d/1tsBz8WUSEHwU3lYAXedtvD-pk4IebusAv2XaRyF_nXg/edit?usp=sharing)
- Meanwhile, I generate a data matrix $X$ consisting of variables generated randomly from a normal distribution without knowing the number you enter. 
- I claim that I can use a model to predict the number you enter perfectly using my $X$!


## Read Data
```{r}
#| code-fold: false
set.seed(17)
# Generate an X matrix randomly from the standard normal distribution
X=matrix(rnorm(40*34), 40, 34)
colnames(X) = paste("V", sep="", 1:34)

#the code used in class
#y=read_sheet("https://docs.google.com/spreadsheets/d/1tsBz8WUSEHwU3lYAXedtvD-pk4IebusAv2XaRyF_nXg/edit?usp=sharing")$randnumber_day8

#read the downloaded data
y=read.csv("data/randnumber_from_students_ICSSummerDA2024.csv")$randnumber_day8
```

## Training vs Testing Data
```{r}
#| code-fold: false
#split the data into training and testing
#training: students 1:35 
#testing: the teaching team 36-40
data.training=data.frame(y=y[1:35], X=X[1:35,])
data.testing=data.frame(y=y[-c(1:35)], X=X[-c(1:35),])
```

- Training data: the data to be used to build a predictive model.
  - In our experiment, the response variable consists of the numbers entered by the 35 students. 
- Testing: the data to be used to test a model. 
  - In our experiment, the response variable consists of the numbers entered by the teaching team (myself and four assistants).  

## Fit a Linear model using the training datat and check its performance
- Next, we fit a linear model using the training data 

- Then, test its performance for the training data

## Fit a Linear model using the training datat and check its performance

```{r}
#| fig-align: center
#fit a model using the training model and predict for the training data
obj.lm=lm(y~ ., data=data.training)
par(mfrow=c(1,2))
plot(data.training$y, predict(obj.lm), xlab="observed", ylab="predicted",
     main="predict the training data", type="b")
abline(0,1)

plot(data.training$y, predict(obj.lm, new=data.training[,-1]), 
     xlab="observed", ylab="predicted",
     main="predict the testing data", xlim=c(-999, 500),  ylim=c(-999, 500))
abline(0,1)
```

## The performance of the model for the training data

- I am able to predict the number you entered perfectly! Surprised?

- Note: the left figure is not easy to read because of the outlier so we look at the plot without the outlier (the right figure).



## The performance of the model for the testing data

```{r}
#| fig-align: center

#predict the testing data
plot(data.testing$y, predict(obj.lm, new=data.testing[,-1]), 
     xlab="observed", ylab="predicted",
     main="predict the testing data")
abline(0,1)
```
- The model we built using the students / training data does not work for the testing data. 

## Overfitting
- In this experiment, the training data has $n=35$ and $p=35$ (including the intercept). 
- When $n\le p$, we can obtain a "perfect" model for the data.
- But this model has poor generalizabition, i.e., it is not able to predict well for new data. 

# More Examples of Overfitting
- Two data points (n=2), two parameters ($\beta_0$ and $\beta_1$): $y_i=\beta_0 + \beta_1 x_i + \epsilon_i$

```{r}
#| fig-align: center

x=rnorm(2)
y=rnorm(2) # has no relationship with x
plot(y, predict(lm(y~x)), xlab="observed", ylab="predicted", type="b", pch=14)
abline(0,1)
```

# More Examples of Overfitting
- Three data points (n=3), three parameters ($\beta_0$, $\beta_1$, and $\beta_2$): $y_i=\beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \epsilon_i$

- Note: this is a 2nd order polynomial

```{r}
#| fig-align: center
x=rnorm(3)
y=rnorm(3) # has no relationship with x
y.pred=predict(lm(y~x+x^2))
my.dataframe=data.frame(x, y, y.pred)
ggplot(my.dataframe) +
  geom_point(aes(x,y), size=4) +
  stat_smooth(aes(x,y), method="lm", se=FALSE, 
              formula = y~ poly(x, 2, raw=TRUE), color="red")
```

# More Examples of Overfitting
- Four data points (n=4), four parameters ($\beta_0$, $\beta_1$, $\beta_2$, and $\beta_3$): $y_i=\beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \beta_3 x_i^3 + \epsilon_i$


- Note: this is a 3rd order polynomial
```{r}
#| fig-align: center
x=rnorm(4)
y=rnorm(4) # has no relationship with x

# a 3rd order polynomial
y.pred=predict(lm(y~x+x^2+x^3))
my.dataframe=data.frame(x, y, y.pred)
ggplot(my.dataframe) +
  geom_point(aes(x,y), size=4) +
  stat_smooth(aes(x,y), method="lm", se=FALSE, 
              formula = y~ poly(x, 3, raw=TRUE), color="red")
```

## How to avoid overfitting

::: {style="font-size: 75%; color: lightgray"}
- There are many methods, for example
  - regularization: introduce a penalty term to reduce model complexity. E.g.,
    - penalize the magnitudes of coefficients such as L$^1$ (LASSO) and L$^2$ (ridge) penalty
    - penalize the number of non-zero coefficients
  - use simpler models
  - variable selection
  - randomly select features to build many models and then ensemble the models
- Cross validation is a useful technique

Check the following link if you would like to learn more:
[Example](http://www.sthda.com/english/articles/36-classification-methods-essentials/149-penalized-logistic-regression-essentials-in-r-ridge-lasso-and-elastic-net/#google_vignette)
:::


